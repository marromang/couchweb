### cbexport ###
cbexport [--version] [--help] <command> [<args>]

Con cbexport se pueden exportar los datos en diversos formatos. El más utlizado es json.
### cbexport json ###
cbexport json [--cluster <url>] [--bucket <bucket_name>][--format <data_format>]
              [--username <username>][--password <password>]
              [--include-key <key>][--cacert <path>][--no-ssl-verify]
              [--threads <num>][--log-file <path>]

El comando copia documentos JSON ya existentes a un fichero con un documento por línea o un fichero que tiene una lista en JSON en la que cada elemento es un documento. 

Opciones obligatorias
-c,--cluster <url>  host del nodo del cluster del que se van a exportar los datos.
-u,--username <username>  usuario del cluster. Necesita tener los permisos adecuados.
-p,--password <password>  contraseña del usuario anterior.
-b,--bucket <bucket_name>   nombre del bucket.
-f,--format <format>  formato de los datos (lineas o lista)
-o,--output <path>  fichero en el que se guardarán los datos exportados


Formato de host
Al especificar un host al comando cbexport, podemos ponerlo de 3 formas:
    couchbase://<addr> (la mas recomendada si se comunica por el puerto por defecto)
    <addr>:<port>
    http://<addr>:<port>

Formato de datos
  Lines
    Contiene un documento JSON por línea en el fichero.
      {"key": "mykey1", "value": "myvalue1"}
      {"key": "mykey2", "value": "myvalue2"}
      {"key": "mykey3", "value": "myvalue3"}
      {"key": "mykey4", "value": "myvalue4"}

  Lista
    Contiene una lista donde cada elemento es un documento JSON,
    [
      {
        "key": "mykey1",
        "value": "myvalue1"
      },
      {"key": "mykey2", "value": "myvalue2"},
      {"key": "mykey3", "value": "myvalue3"},
      {"key": "mykey4", "value": "myvalue4"}
    ]

Ejemplos
Exportar con formato de linea con 4 threads
  $ cbexport json -c couchbase://127.0.0.1 -u Administrator -p password -b default -o /data/lines.json -f lines -t 4

Exportar con formato de lista
  $ cbexport json -c couchbase://127.0.0.1 -u Administrator -p password -b default -o /data/list.json -f list 

### cbimport ###
cbimport [--version] [--help] <command> [<args>]

Commandos

cbimport csv: importa desde ficheros csv

cbimport json: importa desde ficheros JSON

### cbimport csv ###

cbimport csv [--cluster <url>] [--bucket <bucket_name>] [--dataset <path>]
          [--username <username>] [--password <password>][--generate-key <key_expr>]
          [--limit-rows <num>] [--skip-rows <num>][--field-separator <char>]
          [--cacert <path>] [--no-ssl-verify] [--threads <num>]
          [--error-log <path>][--log-file <path>]

Description
Importa csv y otros formatos en los que los datos estén separados por comas. Por defecto, en la primera linea del fichero aparcen los nombres de las columnas separados por comas. Para especificar un separador específico se us --field-separator

Options
Opciones obligatorias:
-c,--cluster <url>  host del nodo del cluster del que se van a exportar los datos.
-u,--username <username>  usuario del cluster. Necesita tener los permisos adecuados.
-p,--password <password>  contraseña del usuario anterior.
-b,--bucket <bucket_name>   nombre del bucket.
-d,--dataset <uri>  URI de los datos que van a ser importados (local o URL) Si el un fichero local, tiene que comenzar con file://. Si es una URL, empezará por http:// o https://.

Formato de host
Al especificar un host al comando cbexport, podemos ponerlo de 3 formas:
    couchbase://<addr> (la mas recomendada si se comunica por el puerto por defecto)
    <addr>:<port>
    http://<addr>:<port>

Generación de calves
Se utilizan para asignar una clave unica para cada documento. Se suelen generar combinando columnas, valores arbitrarios o generadores personalizados.
Ejemplo
  Dataset (csv)
    fname,age 
    alice,40 
    barry,36
  Expresión del generador de claves
     --generate-key key::%fname%::#MONO_INCR#
  Claves generadas
    key::alice::1 
    key::barry::2
Se usa el valor de la columan "fname" y un generador personalizado. Para especificar que se va a sustituir "fname", se pone entre %
También contiene la función MONO_INCR, que hace que se incremente en 1 cada vez que se genera una clave
Cualquier texto que esté entre % o # es un texto estático en el resultado. Si una clave requiere tener uno de esos símbolos, hay que ponerlos doblres (%% o ##)
Si una clave no se puede generar porque la columna no exista, se omite esa linea.

Ejemplos
  Usando los siguientes ficheros
    /data/people.csv
      fname,age
      alice,40
      barry,36
    /data/people.tsv
      fname  age
      alice  40
      barry  36

Para importar desde people.csv usando la clave con "fname" y con 4 threads:
$ cbimport csv -c couchbase://127.0.0.1 -u Administrator -p password  -b default -d file:///data/people.csv -g key::%fname% -t 4

Para importar desde people.tsv usando la clave con "fname" y el generadir de UUID:
$ cbimport csv -c couchbase://127.0.0.1 -u Administrator -p password -b default -d file:///data/people.tsv --field-separator $'\t' -g key::%fname%::#UUID# -t 4

Si los datos no están en local, pero si via http (http://data.org/people.csv)
$ cbimport csv -c couchbase://127.0.0.1 -u Administrator -p password -b default -d http://data.org/people.csv -g key::%fname%::#UUID# -t 4

### cbimport json ###
cbimport json [--cluster <url>] [--bucket <bucket_name>] [--dataset <path>]
              [--format <data_format>][--username <username>][--password <password>]
              [--generate-key <key_expr>][--cacert <path>][--no-ssl-verify]
              [--threads <num>] [--error-log <path>][--log-file <path>]

Importa ficheros JSON. Funciona con ficheros que tienen un documento JSON por línea o ficheros con listas JSON donde cada elemento es un documento.
También inclue generación de claves en el fichero importado combinando campos ya existente en el documento y un generador de claves personalizado.

Options obligatorias
-c,--cluster <url>  host del nodo del cluster del que se van a exportar los datos.
-u,--username <username>  usuario del cluster. Necesita tener los permisos adecuados.
-p,--password <password>  contraseña del usuario anterior.
-b,--bucket <bucket_name>   nombre del bucket.
-d,--dataset <uri>  URI de los datos que van a ser importados (local o URL) Si el un fichero local, tiene que comenzar con file://. Si es una URL, empezará por http:// o https://.

-f,--format <format>  formato del fichero (lineas, lista, muestra)

Formato de host
Al especificar un host al comando cbexport, podemos ponerlo de 3 formas:
    couchbase://<addr> (la mas recomendada si se comunica por el puerto por defecto)
    <addr>:<port>
    http://<addr>:<port>

Dataset Formats
The cbimport command supports the following formats:

    Formato de datos
    Lineas
      Contiene un documento JSON por línea en el fichero.
      {"key": "mykey1", "value": "myvalue1"}
      {"key": "mykey2", "value": "myvalue2"}
      {"key": "mykey3", "value": "myvalue3"}
      {"key": "mykey4", "value": "myvalue4"}

  Lista
    Contiene una lista donde cada elemento es un documento JSON,
    [
      {
        "key": "mykey1",
        "value": "myvalue1"
      },
      {"key": "mykey2", "value": "myvalue2"},
      {"key": "mykey3", "value": "myvalue3"},
      {"key": "mykey4", "value": "myvalue4"}
    ]

    Muestra
    Se especifica un ZIP con olos documentos. Está pensado para los buckets de ejemplo de couchbase. A diferencia de las anteriores, contiene vista, indice y definiciones de indices completas. No hay que especificar el directorio con file://. 
    La estructura del directorio es:

    + (root folder)
      + docs
        key1.json
        key2.json
        ...
      + design_docs
        indexes.json
        views.json

      Todos los documentos en este formato están en el mismo directorio y solo hay un fichero por documento. El nombre del fichero es la clave para el documento JSON del fichero.
      El directorio design_docs tiene los indices. El fichero  indexes.json está reservado para indices secundarios. Todos los demas ficheros están reservados para vistas 

Generación de claves
Se utilizan para asignar una clave unica para cada documento. Se suelen generar combinando columnas, valores arbitrarios o generadores personalizados.
Ejemplo
  Dataset
    {
      "name": "alice",
      "age": 40
    }
  Expresión del generador de claves
     --generate-key key::%fname%::#MONO_INCR#
  Claves generadas
    key::alice::1 

Se usa el valor de la columan "fname" y un generador personalizado. Para especificar que se va a sustituir "fname", se pone entre %
También contiene la función MONO_INCR, que hace que se incremente en 1 cada vez que se genera una clave
Cualquier texto que esté entre % o # es un texto estático en el resultado. Si una clave requiere tener uno de esos símbolos, hay que ponerlos doblres (%% o ##)
Si una clave no se puede generar porque la columna no exista, se omite esa linea.

Ejemplos
Ficheros de prueba:
  /data/lines.json
    {"name": "alice", "age": 37}
    {"name": "bob", "age": 39}
  /data/list.json
    [
      {"name": "candice", "age": 42},
      {"name": "daniel", "age": 38}
    ]

Para importar de /data/lines.json usando como clave "name" y con 4 threads
$ cbimport json -c couchbase://127.0.0.1 -u Administrator -p password -b default -d file:///data/lines.json -f lines -g key::%name% -t 4

Para importar de /data/lines.json usando como clave "name" y el generador de UUID
$ cbimport json -c couchbase://127.0.0.1 -u Administrator -p password -b default -d file:///data/list.json -f list -g key::%name%::#UUID# -t 4

Si los datos no están en local, pero si via http (http://data.org/list.json)
$ cbimport json -c couchbase://127.0.0.1 -u Administrator -p password \
   -b default -d http://data.org/list.json -f list -g key::%name%::#UUID# -t 4


